{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MINILEAVES.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fSP6y6dFhGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqS6ASRRfHNV",
        "colab_type": "code",
        "outputId": "72072df2-c6b0-45b4-fa7b-197bebecfe9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4S7wWSWYeKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "\n",
        "class data_files(Dataset):\n",
        "  def __init__(self, img_path, label_path, transforms=None, mode='train'):\n",
        "    super(Dataset, self).__init__()\n",
        "    self.img_path = img_path\n",
        "    self.images = np.load(self.img_path)\n",
        "    if mode == 'train':\n",
        "      self.label_path = label_path\n",
        "      self.labels = torch.from_numpy(np.load(self.label_path))\n",
        "\n",
        "    self.transforms = transforms\n",
        "    self.mode = mode\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.images.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img = self.images[index, ...]\n",
        "    if self.transforms != None:\n",
        "      img = self.transforms(img)\n",
        "    \n",
        "    if self.mode == 'train':\n",
        "      label = self.labels[index]\n",
        "      return img, label\n",
        "    elif self.mode == 'test':\n",
        "      return img\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26orRO0YePtg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "\n",
        "img_transforms = transforms.Compose([\n",
        "                                    transforms.ToPILImage(),\n",
        "                                    transforms.RandomRotation(30),\n",
        "                                    transforms.ColorJitter(),\n",
        "                                    transforms.RandomHorizontalFlip(),\n",
        "                                    transforms.RandomVerticalFlip(),                             \n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                                  ])\n",
        "\n",
        "img_path = 'drive/My Drive/data/train-images.npy'\n",
        "label_path = 'drive/My Drive/data/train-labels.npy'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59i__wUsf5xk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = data_files(img_path, label_path, transforms=img_transforms, mode='train') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGBdeRPXgYBo",
        "colab_type": "code",
        "outputId": "a6816341-a277-4e37-d6d6-8bdd39b4c5a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset.__len__()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43466"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTAx8rnpgvi9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "# needed more data for training thus reduced validation split\n",
        "validation_split = .05\n",
        "shuffle_dataset = True\n",
        "random_seed= 42\n",
        "BATCH = 512\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "trainsampler = SubsetRandomSampler(train_indices)\n",
        "validsampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH, \n",
        "                                           sampler=trainsampler, num_workers=1)\n",
        "validloader = torch.utils.data.DataLoader(dataset, batch_size=BATCH,\n",
        "                                                sampler=validsampler, num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpHUFHbOhNxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torchvision.models.densenet201(pretrained=True, progress=True)\n",
        "model.classifier = nn.Sequential(\n",
        "                         nn.Linear(in_features=1920, out_features=2048),\n",
        "                         nn.ReLU(True),\n",
        "                         nn.Dropout(p=0.2),\n",
        "                         nn.Linear(in_features=2048, out_features=38))\n",
        "model = model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6yM7TrAhb2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atA4yIndid7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(trainloader, model, criterion, optimizer):\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  losses = 0\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "    inputs, targets = inputs.cuda(), targets.cuda()\n",
        "    \n",
        "    outputs = model(inputs)\n",
        "    if batch_idx % 10 == 0:\n",
        "      print(batch_idx, losses)\n",
        "    \n",
        "    loss =  criterion(outputs, targets)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    \n",
        "    total += targets.size(0)\n",
        "    correct += (predicted == targets).sum()\n",
        "    losses += loss.item()*inputs.size(0)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  return (losses / total, 100.0 * correct / total)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVCMMUTki0a3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(validloader, model, criterion):\n",
        "  model.eval()\n",
        "\n",
        "  losses = 0\n",
        "  total = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, (inputs, targets) in enumerate(validloader):\n",
        "      inputs, targets = inputs.cuda(), targets.cuda()\n",
        "      \n",
        "      outputs = model(inputs)\n",
        "      loss =  criterion(outputs, targets)\n",
        "\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      \n",
        "      total += targets.size(0)\n",
        "      correct += (predicted == targets).sum()\n",
        "      losses += loss.item()*inputs.size(0)\n",
        "    \n",
        "\n",
        "  return (losses / total, 100.0 * correct / total)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWkX8r1Fi2td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_EPOCHS = 4\n",
        "def run_model(trainloader, validloader, model, criterion, optimizer):\n",
        "  import time\n",
        "  train_losses = []\n",
        "  train_accuracy = []\n",
        "\n",
        "  valid_losses = []\n",
        "  valid_accuracy = []\n",
        "\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "    st = time.time()\n",
        "    tlosses, tacc = train(trainloader, model, criterion, optimizer)\n",
        "    # scheduler.step()/\n",
        "    vlosses, vacc = validate(validloader, model, criterion)\n",
        "    print('Epoch: {}:: train_loss: {}, train_accuracy: {} \\n valid_loss: {}, valid_accuracy: {}'.format(\n",
        "        epoch, tlosses, tacc,\n",
        "        vlosses, vacc\n",
        "    ))\n",
        "    train_losses.append(tlosses)\n",
        "    train_accuracy.append(tacc)\n",
        "    valid_losses.append(vlosses)\n",
        "    valid_accuracy.append(vacc)\n",
        "    \n",
        "    en = time.time()\n",
        "    print(\"epoch took:\", en - st)\n",
        "\n",
        "  return {\n",
        "      'train' : (train_losses, train_accuracy),\n",
        "      'val'  : (valid_losses, valid_accuracy),\n",
        "  }\n",
        "\n",
        "result = run_model(trainloader, validloader, model, criterion, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQI6L93xPMoD",
        "colab_type": "text"
      },
      "source": [
        "Use color jitter augmentations for some epochs and then remove it from the augmentations and train some more"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB7Nixcki94l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), 'drive/My Drive/aicrowd_blitz/minileaves/model.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cqwm75Tgu4P3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "\n",
        "testset = data_files('drive/My Drive/data/test-images.npy', None, transforms=img_transforms, mode='test')\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=512, \n",
        "                                           shuffle=False, num_workers=4)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG-VwomPEO7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "preds = []\n",
        "with torch.no_grad():\n",
        "    for images in testloader:\n",
        "        data = images.cuda()\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        pr = predicted.detach().cpu().numpy()\n",
        "        for i in pr:\n",
        "          preds.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzj_-58jHkVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(np.array(preds)).to_csv('drive/My Drive/data/densenet201-submission.csv', header=['class_index'])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}